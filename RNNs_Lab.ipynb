{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbfec32-1b50-43e9-a648-c9879dc4b79c",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1eb792b-8cfc-44d8-9d1c-0bf8c403fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7705c2-42a1-4047-bbac-3a0f7465e032",
   "metadata": {},
   "source": [
    "# Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31467209-c5d3-4a4f-a79f-4a2f6e68ce85",
   "metadata": {},
   "source": [
    "### Load Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ef01310-47d6-44ac-aff1-abf4da07a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets, train_labels = [], []\n",
    "\n",
    "pos = os.getcwd() + '/corpus/arabic_tweets/pos/'  # Replace with the actual directory path\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(pos):\n",
    "    if filename.endswith('.txt'):  # Select only text files\n",
    "        file_path = os.path.join(pos, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "            file_content = file.read()\n",
    "            train_tweets.append(file_content)\n",
    "            train_labels.append(\"positive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d463c-377c-4730-9398-cb5fcaa5e44b",
   "metadata": {},
   "source": [
    "### Load Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "937bb606-b07a-4e7e-a83a-1ccce2b18263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the txt file negative tweet\n",
    "pos = os.getcwd() + '/corpus/arabic_tweets/neg/'  # Replace with the actual directory path\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(pos):\n",
    "    if filename.endswith('.txt'):  # Select only text files\n",
    "        file_path = os.path.join(pos, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "            file_content = file.read()\n",
    "            train_tweets.append(file_content)\n",
    "            train_labels.append(\"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e8e33-f28b-4402-ab6d-f4925c1db165",
   "metadata": {},
   "source": [
    "### Build a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "743b5741-d234-4d22-a833-76ec742cd6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ù†Ø­Ù† Ø§Ù„Ø°ÙŠÙ† ÙŠØªØ­ÙˆÙ„ ÙƒÙ„ Ù…Ø§ Ù†ÙˆØ¯ Ø£Ù† Ù†Ù‚ÙˆÙ„Ù‡ Ø¥Ù„Ù‰ Ø¯Ø¹Ø§Ø¡ Ù„Ù„...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÙˆÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„Ù† ÙŠØ¨Ù‚Ù‰Ù° Ù…Ø¹Ùƒ Ø¢Ø­Ø¯Ø¥Ù„Ø§ Ù…Ù† Ø±Ø£Ù‰Ù° Ø§Ù„Ø¬Ù…Ø§Ù„...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù†Ù…Ø´ Ù†Ù†ÙˆÙ… Ù…Ø§ Ø¯Ø§ Ø¯ÙŠÙ„ ÙˆÙ„Ø§Ø¯Ù†Ø§ ğŸ’š\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ØªØ¹Ø¯Ù„ Ø§Ù„Ù†Øª ÙˆØ´ÙØªÙ‡Ø§ âœŒ\\n</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ğŸ¥ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙŠ \"Ø¬Ø¯Ø©\" âœ”ğŸ’ªğŸ¼ ğŸ’™ #Ø§Ù„Ù‡Ù„Ø§Ù„ #ÙÙŠØ¯ÙŠÙˆ_...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets    Labels\n",
       "0  Ù†Ø­Ù† Ø§Ù„Ø°ÙŠÙ† ÙŠØªØ­ÙˆÙ„ ÙƒÙ„ Ù…Ø§ Ù†ÙˆØ¯ Ø£Ù† Ù†Ù‚ÙˆÙ„Ù‡ Ø¥Ù„Ù‰ Ø¯Ø¹Ø§Ø¡ Ù„Ù„...  positive\n",
       "1  ÙˆÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ù„Ù† ÙŠØ¨Ù‚Ù‰Ù° Ù…Ø¹Ùƒ Ø¢Ø­Ø¯Ø¥Ù„Ø§ Ù…Ù† Ø±Ø£Ù‰Ù° Ø§Ù„Ø¬Ù…Ø§Ù„...  positive\n",
       "2                      Ù†Ù…Ø´ Ù†Ù†ÙˆÙ… Ù…Ø§ Ø¯Ø§ Ø¯ÙŠÙ„ ÙˆÙ„Ø§Ø¯Ù†Ø§ ğŸ’š\\n  positive\n",
       "3                               ØªØ¹Ø¯Ù„ Ø§Ù„Ù†Øª ÙˆØ´ÙØªÙ‡Ø§ âœŒ\\n  positive\n",
       "4  ğŸ¥ Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙŠ \"Ø¬Ø¯Ø©\" âœ”ğŸ’ªğŸ¼ ğŸ’™ #Ø§Ù„Ù‡Ù„Ø§Ù„ #ÙÙŠØ¯ÙŠÙˆ_...  positive"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dic = {\n",
    "    'Tweets' : train_tweets,\n",
    "    'Labels' : train_labels\n",
    "}\n",
    "\n",
    "train_corpus = pd.DataFrame(train_dic)\n",
    "train_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b046ada-13fc-45d2-9056-b4115de8e812",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "##### Explore your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d563b-a771-43b4-8e43-3688275b1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8d4a6-89a4-47b1-bf43-08dc09b97506",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8d9fa-6fb7-4352-aadb-3abeb932c412",
   "metadata": {},
   "source": [
    "### Shuffle all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246bb815-274b-43a3-9d60-967a5864a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10a499-afa6-4d35-aa8a-53dbcae8e557",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "**Hint: remove URLs, Hashtags, alphanumeric characters, punctuation marks, stop words, extra spaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b0161-4c2d-4f33-90a3-e8892a27455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0cb63",
   "metadata": {},
   "source": [
    "#### Extra: you could do stemming or lemmatization before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485120c-47f1-43e9-b6c1-cbe0a69f04c7",
   "metadata": {},
   "source": [
    "# Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e73af-8d88-4928-8243-6f456fc6de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160549cf-bffd-4205-a8fa-a6aa0695bcd8",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f152bfd-478f-4cdd-b17e-885d4649019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba90d2-7712-4e80-9120-c82f495b5f66",
   "metadata": {},
   "source": [
    "# Text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2fb10-2a1a-4201-8d23-a3301dcb51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c31c7d-0375-4ef2-9f51-dccef70793d3",
   "metadata": {},
   "source": [
    "# Pad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05e3c6-6f92-4a49-a904-f0af742ffe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d0909-8e90-4aef-9ddb-42c3597791cb",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47efb8b2-7635-48ba-a4ae-4118862e74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a35492-747b-4fea-a80c-1602ff36da21",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5fb34-e15c-45cf-bf39-5a4c65a28705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e105a33-8de7-406f-a5fb-c1a558c7bb9d",
   "metadata": {},
   "source": [
    "# Evaulation and Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a956b35-0604-44d5-87f2-eacfb36870d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code ^_^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
